{"version":3,"file":"foreground.js","mappings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z1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":["webpack://prompt-gpt/./node_modules/easy-speech/dist/EasySpeech.js","webpack://prompt-gpt/webpack/bootstrap","webpack://prompt-gpt/webpack/runtime/define property getters","webpack://prompt-gpt/webpack/runtime/hasOwnProperty shorthand","webpack://prompt-gpt/webpack/runtime/make namespace object","webpack://prompt-gpt/./src/foreground/foreground.js"],"sourcesContent":["/**\n * @module EasySpeech\n * @typicalname EasySpeech\n */\n\n/**\n * Cross browser Speech Synthesis with easy API.\n * This project was created, because it's always a struggle to get the synthesis\n * part of `Web Speech API` running on most major browsers.\n *\n * Setup is very straight forward (see example).\n *\n * @example\n * import EasySpeech from 'easy-speech'\n *\n * const example = async () => {\n *   await EasySpeech.init() // required\n *   await EasySpeech.speak({ 'Hello, world' })\n * }\n *\n * @see https://wicg.github.io/speech-api/#tts-section\n * @see https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesis\n * @type {Object}\n */\nconst EasySpeech = {};\n\n/**\n * To support multiple environments (browser, node) we define scope, based\n * on what's available with window as priority, since Browsers are main target.\n * @private\n */\nconst scope = typeof globalThis === 'undefined' ? window : globalThis;\n\n/**\n * @private\n * @type {{\n *  status: String,\n    initialized: Boolean,\n    speechSynthesis: null|SpeechSynthesis,\n    speechSynthesisUtterance: null|SpeechSynthesisUtterance,\n    speechSynthesisVoice: null|SpeechSynthesisVoice,\n    speechSynthesisEvent: null|SpeechSynthesisEvent,\n    speechSynthesisErrorEvent: null|SpeechSynthesisErrorEvent,\n    voices: null|Array<SpeechSynthesisVoice>,\n    defaults: {\n      pitch: Number,\n      rate: Number,\n      volume: Number,\n      voice: null|SpeechSynthesisVoice\n    },\n    handlers: {}\n * }}\n */\nconst internal = {\n  status: 'created'\n};\n\nconst patches = {};\n\n/*******************************************************************************\n *\n * AVAILABLE WITHOUT INIT\n *\n ******************************************************************************/\n\n/**\n * Enable module-internal debugging by passing your own callback function.\n * Debug will automatically pass through all updates to `status`\n *\n * @example\n * import EasySpeech from 'easy-speech'\n * import Log from '/path/to/my/Log'\n *\n * EasySpeech.debug(arg => Log.debug('EasySpeech:', arg))\n *\n * @param {Function} fn A function, which always receives one argument, that\n *  represents a current debug message\n */\nEasySpeech.debug = fn => {\n  debug = typeof fn === 'function' ? fn : () => {};\n};\n\nlet debug = () => {};\n\n/**\n * Detects all possible occurrences of the main Web Speech API components\n * in the global scope.\n *\n * The returning object will have the following structure (see example).\n *\n * @example\n * EasySpeech.detect()\n *\n * {\n *     speechSynthesis: SpeechSynthesis|undefined,\n *     speechSynthesisUtterance: SpeechSynthesisUtterance|undefined,\n *     speechSynthesisVoice: SpeechSynthesisVoice|undefined,\n *     speechSynthesisEvent: SpeechSynthesisEvent|undefined,\n *     speechSynthesisErrorEvent: SpeechSynthesisErrorEvent|undefined,\n *     onvoiceschanged: Boolean,\n *     onboundary: Boolean,\n *     onend: Boolean,\n *     onerror: Boolean,\n *     onmark: Boolean,\n *     onpause: Boolean,\n *     onresume: Boolean,\n *     onstart: Boolean\n * }\n *\n * @returns {object} An object containing all possible features and their status\n */\nEasySpeech.detect = () => detectFeatures();\n\n/** @private **/\nconst detectFeatures = () => {\n  const features = {}\n  ;[\n    'speechSynthesis',\n    'speechSynthesisUtterance',\n    'speechSynthesisVoice',\n    'speechSynthesisEvent',\n    'speechSynthesisErrorEvent'\n  ].forEach(feature => {\n    features[feature] = detect(feature);\n  });\n\n  features.onvoiceschanged = hasProperty(features.speechSynthesis, 'onvoiceschanged');\n\n  const hasUtterance = hasProperty(features.speechSynthesisUtterance, 'prototype');\n\n  utteranceEvents.forEach(event => {\n    const name = `on${event}`;\n    features[name] = hasUtterance && hasProperty(features.speechSynthesisUtterance.prototype, name);\n  });\n\n  // not published to the outside\n  patches.isAndroid = isAndroid();\n  patches.isFirefox = isFirefox() || isKaiOS();\n  patches.isSafari = isSafari();\n\n  debug(`is android: ${!!patches.isAndroid}`);\n  debug(`is firefox: ${!!patches.isFirefox}`);\n  debug(`is safari: ${!!patches.isSafari}`);\n\n  return features\n};\n\n/** @private **/\nconst hasProperty = (target = {}, prop) => Object.hasOwnProperty.call(target, prop) || prop in target || !!target[prop];\n\n/** @private **/\nconst getUA = () => (scope.navigator || {}).userAgent || '';\n\n/** @private **/\nconst isAndroid = () => /android/i.test(getUA());\n\n/** @private **/\nconst isKaiOS = () => /kaios/i.test(getUA());\n\n/** @private **/\nconst isFirefox = () => {\n  // InstallTrigger will soon be deprecated\n  if (typeof scope.InstallTrigger !== 'undefined') {\n    return true\n  }\n\n  return /firefox/i.test(getUA())\n};\n\n/** @private **/\nconst isSafari = () => typeof scope.GestureEvent !== 'undefined';\n\n/**\n * Common prefixes for browsers that tend to implement their custom names for\n * certain parts of their API.\n * @private\n **/\nconst prefixes = ['webKit', 'moz', 'ms', 'o'];\n\n/**\n * Make the first character of a String uppercase\n * @private\n **/\nconst capital = s => `${s.charAt(0).toUpperCase()}${s.slice(1)}`;\n\n/**\n * Find a feature in global scope by checking for various combinations and\n * variations of the base-name\n * @param {String} baseName name of the component to look for, must begin with\n *   lowercase char\n * @return {Object|undefined} The component from global scope, if found\n * @private\n **/\nconst detect = baseName => {\n  const capitalBaseName = capital(baseName);\n  const baseNameWithPrefixes = prefixes.map(p => `${p}${capitalBaseName}`);\n  const found = [baseName, capitalBaseName]\n    .concat(baseNameWithPrefixes)\n    .find(inGlobalScope);\n\n  return scope[found]\n};\n\n/**\n * Returns, if a given name exists in global scope\n * @private\n * @param name\n * @return {boolean}\n */\nconst inGlobalScope = name => scope[name];\n\n/**\n * Returns a shallow copy of the current internal status. Depending of the\n * current state this might return an object with only a single field `status`\n * or a complete Object, including detected features, `defaults`, `handlers`\n * and supported `voices`.\n *\n * @example\n * import EasySpeech from 'easy-speech'\n *\n * // uninitialized\n * EasySpeech.status() // { status: 'created' }\n *\n * // after EasySpeech.init\n * EasySpeech.status()\n *\n * {\n *   status: 'init: complete',\n *   initialized: true,\n *   speechSynthesis: speechSynthesis,\n *   speechSynthesisUtterance: SpeechSynthesisUtterance,\n *   speechSynthesisVoice: SpeechSynthesisVoice,\n *   speechSynthesisEvent: SpeechSynthesisEvent,\n *   speechSynthesisErrorEvent: SpeechSynthesisErrorEvent,\n *   voices: [...],\n *   defaults: {\n *     pitch: 1,\n *     rate: 1,\n *     volume: 1,\n *     voice: null\n *   },\n *   handlers: {}\n * }\n *\n * @return {Object} the internal status\n */\nEasySpeech.status = () => ({ ...internal });\n\n/**\n * Updates the internal status\n * @private\n * @param {String} s the current status to set\n */\nconst status = s => {\n  debug(s);\n  internal.status = s;\n};\n\n/**\n * This is the function you need to run, before being able to speak.\n * It includes:\n * - feature detection\n * - feature assignment (into internal state)\n * - voices loading\n * - state update\n * - inform caller about success\n *\n * It will load voices by a variety of strategies:\n *\n * - detect and that SpeechSynthesis is basically supported, if not -> fail\n * - load voices directly\n * - if not loaded but `onvoiceschanged` is available: use `onvoiceschanged`\n * - if `onvoiceschanged` is not available: fallback to timeout\n * - if `onvoiceschanged` is fired but no voices available: fallback to timeout\n * - timeout reloads voices in a given `interval` until a `maxTimeout` is reached\n * - if voices are loaded until then -> complete\n * - if no voices found -> fail\n *\n * Note: if once initialized you can't re-init (will skip and resolve to\n * `false`) unless you run `EasySpeech.reset()`.\n *\n * @param maxTimeout {number}[5000] the maximum timeout to wait for voices in ms\n * @param interval {number}[250] the interval in ms to check for voices\n * @param quiet {boolean=} prevent rejection on errors, e.g. if no voices\n * @return {Promise<Boolean>}\n * @fulfil {Boolean} true, if initialized, false, if skipped (because already\n *   initialized)\n * @reject {Error} - The error `message` property will always begin with\n *   `EasySpeech: ` and contain one of the following:\n *\n *   - `browser misses features` - The browser will not be able to use speech\n *      synthesis at all as it misses crucial features\n *   - `browser has no voices (timeout)` - No voice could be loaded with neither\n *      of the given strategies; chances are high the browser does not have\n *      any voices embedded (example: Chromium on *buntu os')\n */\n\nEasySpeech.init = function ({ maxTimeout = 5000, interval = 250, quiet } = {}) {\n  return new Promise((resolve, reject) => {\n    if (internal.initialized) { return resolve(false) }\n    EasySpeech.reset();\n    status('init: start');\n\n    // there may be the case, that the browser needs to load using a timer\n    // so we declare it at the top to make sure the interval is always cleared\n    // when we exit the Promise via fail / complete\n    let timer;\n    let voicesChangedListener;\n    let completeCalled = false;\n\n    const fail = (errorMessage) => {\n      status(`init: failed (${errorMessage})`);\n      clearInterval(timer);\n      internal.initialized = false;\n\n      // we have the option to fail quiet here\n      return quiet\n        ? resolve(false)\n        : reject(new Error(`EasySpeech: ${errorMessage}`))\n    };\n\n    const complete = () => {\n      // avoid race-conditions between listeners and timeout\n      if (completeCalled) { return }\n      status('init: complete');\n\n      // set flags immediately\n      completeCalled = true;\n      internal.initialized = true;\n\n      // cleanup events and timer\n      clearInterval(timer);\n      speechSynthesis.onvoiceschanged = null;\n\n      if (voicesChangedListener) {\n        speechSynthesis.removeEventListener('voiceschanged', voicesChangedListener);\n      }\n\n      // all done\n      return resolve(true)\n    };\n\n    // before initializing we force-detect all required browser features\n    const features = detectFeatures();\n    const hasAllFeatures = !!features.speechSynthesis && !!features.speechSynthesisUtterance;\n\n    if (!hasAllFeatures) {\n      return fail('browser misses features')\n    }\n\n    // assign all detected features to our internal definitions\n    Object.keys(features).forEach(feature => {\n      internal[feature] = features[feature];\n    });\n\n    // start initializing\n    const { speechSynthesis } = internal;\n    const voicesLoaded = () => {\n      const voices = speechSynthesis.getVoices() || [];\n      if (voices.length > 0) {\n        internal.voices = voices;\n        status(`voices loaded: ${voices.length}`);\n\n        // if we find a default voice, set it as default\n        internal.defaultVoice = voices.find(v => v.default);\n\n        // otherwise let's stick to the first one we can find by locale\n        if (!internal.defaultVoice) {\n          const language = (scope.navigator || {}).language || '';\n          const lang = language.split('-')[0];\n\n          internal.defaultVoice = voices.find(v => {\n            return v.lang && (v.lang.indexOf(`${lang}-`) > -1 || v.lang.indexOf(`${lang}_`) > -1)\n          });\n        }\n\n        // otherwise let's use the first element in the array\n        if (!internal.defaultVoice) {\n          internal.defaultVoice = voices[0];\n        }\n\n        return true\n      }\n      return false\n    };\n\n    status('init: voices');\n\n    // best case: detect if voices can be loaded directly\n    if (voicesLoaded()) { return complete() }\n\n    // last possible fallback method: run a timer until max. timeout and reload\n    const loadViaTimeout = () => {\n      status('init: voices (timer)');\n      let timeout = 0;\n      timer = setInterval(() => {\n        if (voicesLoaded()) {\n          return complete()\n        }\n\n        if (timeout > maxTimeout) {\n          return fail('browser has no voices (timeout)')\n        }\n\n        timeout += interval;\n      }, interval);\n    };\n\n    // detect if voices can be loaded after onveoiceschanged,\n    // but only if the browser supports this event\n    if (features.onvoiceschanged) {\n      status('init: voices (onvoiceschanged)');\n\n      speechSynthesis.onvoiceschanged = () => {\n        if (voicesLoaded()) { return complete() }\n\n        // xxx: some browsers (like chrome on android still have not all\n        // voices loaded at this point, whichs is why we need to enter\n        // the timeout-based method here.\n        return loadViaTimeout()\n      };\n\n      // xxx: there is an edge-case where browser provide onvoiceschanged,\n      // but they never load the voices, so init would never complete\n      // in such case we need to fail after maxTimeout\n      setTimeout(() => {\n        if (voicesLoaded()) {\n          return complete()\n        }\n        return fail('browser has no voices (timeout)')\n      }, maxTimeout);\n    } else {\n      // this is a very problematic case, since we don't really know, whether\n      // this event will fire at all, so we need to setup both a listener AND\n      // run the timeout and make sure on of them \"wins\"\n      // affected browsers may be: MacOS Safari\n      if (hasProperty(speechSynthesis, 'addEventListener')) {\n        status('init: voices (addEventListener)');\n\n        voicesChangedListener = () => {\n          if (voicesLoaded()) { return complete() }\n        };\n\n        speechSynthesis.addEventListener('voiceschanged', voicesChangedListener);\n      }\n\n      // for all browser not supporting onveoiceschanged we start a timer\n      // until we reach a certain timeout and try to get the voices\n      loadViaTimeout();\n    }\n  })\n};\n\n/**\n * Placed as first line in functions that require `EasySpeech.init` before they\n * can run.\n * @param {boolean=} force set to true to force-skip check\n * @private\n */\nconst ensureInit = ({ force } = {}) => {\n  if (!force && !internal.initialized) {\n    throw new Error('EasySpeech: not initialized. Run EasySpeech.init() first')\n  }\n};\n\n/*******************************************************************************\n *\n * AVAILABLE ONLY AFTER INIT\n *\n ******************************************************************************/\n\n/**\n * Returns all available voices.\n *\n * @condition `EasySpeech.init` must have been called and resolved to `true`\n * @return {Array<SpeechSynthesisVoice>}\n */\nEasySpeech.voices = () => {\n  ensureInit();\n  return internal.voices\n};\n\n/**\n * Attaches global/default handlers to every utterance instance. The handlers\n * will run in parallel to any additional handlers, attached when calling\n * `EasySpeech.speak`\n *\n * @condition `EasySpeech.init` must have been called and resolved to `true`\n *\n * @param {Object} handlers\n * @param {function=} handlers.boundary - optional, event handler\n * @param {function=} handlers.end - optional, event handler\n * @param {function=} handlers.error - optional, event handler\n * @param {function=} handlers.mark - optional, event handler\n * @param {function=} handlers.pause - optional, event handler\n * @param {function=} handlers.resume - optional, event handler\n * @param {function=} handlers.start - optional, event handler\n *\n * @return {Object} a shallow copy of the Object, containing all global handlers\n */\nEasySpeech.on = (handlers) => {\n  ensureInit();\n\n  utteranceEvents.forEach(name => {\n    const handler = handlers[name];\n    if (validate.handler(handler)) {\n      internal.handlers[name] = handler;\n    }\n  });\n\n  return { ...internal.handlers }\n};\n\n/**\n * We use these keys to search for these events in handler objects and defaults\n * @private\n */\nconst utteranceEvents = [\n  'boundary',\n  'end',\n  'error',\n  'mark',\n  'pause',\n  'resume',\n  'start'\n];\n\n/**\n * Internal validation of passed parameters\n * @private\n */\nconst validate = {\n  isNumber: n => typeof n === 'number' && !Number.isNaN(n),\n  pitch: p => validate.isNumber(p) && p >= 0 && p <= 2,\n  volume: v => validate.isNumber(v) && v >= 0 && v <= 1,\n  rate: r => validate.isNumber(r) && r >= 0.1 && r <= 10,\n  text: t => typeof t === 'string',\n  handler: h => typeof h === 'function',\n  // we prefer duck typing here, mostly because there are cases where\n  // SpeechSynthesisVoice is not defined on global scope but is supported\n  // when using getVoices().\n  voice: v => v && v.lang && v.name && v.voiceURI\n};\n\n/**\n * Sets defaults for utterances. Invalid values will be ignored without error\n * or warning.\n *\n * @see https://wicg.github.io/speech-api/#utterance-attributes\n * @param {object=} options - Optional object containing values to set values\n * @param {object=} options.voice - Optional `SpeechSynthesisVoice` instance or\n *  `SpeechSynthesisVoice`-like Object\n * @param {number=} options.pitch - Optional pitch value >= 0 and <= 2\n * @param {number=} options.rate - Optional rate value >= 0.1 and <= 10\n * @param {number=} options.volume - Optional volume value >= 0 and <= 1\n *\n * @return {object} a shallow copy of the current defaults\n */\nEasySpeech.defaults = (options) => {\n  ensureInit();\n\n  if (options) {\n    internal.defaults = internal.defaults || {}\n\n    ;['voice', 'pitch', 'rate', 'volume'].forEach(name => {\n      const value = options[name];\n      const isValid = validate[name];\n\n      if (isValid(value)) {\n        internal.defaults[name] = value;\n      }\n    });\n  }\n\n  return { ...internal.defaults }\n};\n\n/**\n * Determines the current voice and makes sure, there is always a voice returned\n * @private\n * @param voice\n * @return {*|SpeechSynthesisVoice|{}}\n */\nconst getCurrentVoice = voice => voice ||\n  internal.defaults?.voice ||\n  internal.defaultVoice ||\n  internal.voices?.[0];\n\n/**\n * Creates a new `SpeechSynthesisUtterance` instance\n * @private\n * @param text\n */\nconst createUtterance = text => {\n  const UtteranceClass = internal.speechSynthesisUtterance;\n  return new UtteranceClass(text)\n};\n\n/**\n * Speaks a voice by given parameters, constructs utterance by best possible\n * combinations of parameters and defaults.\n *\n * If the given utterance parameters are missing or invalid, defaults will be\n * used as fallback.\n *\n * @example\n * const voice = EasySpeech.voices()[10] // get a voice you like\n *\n * EasySpeech.speak({\n *   text: 'Hello, world',\n *   voice: voice,\n *   pitch: 1.2,  // a little bit higher\n *   rate: 1.7, // a little bit faster\n *   boundary: event => console.debug('word boundary reached', event.charIndex),\n *   error: e => notify(e)\n * })\n *\n * @param {object} options - required options\n * @param {string} text - required text to speak\n * @param {object=} voice - optional `SpeechSynthesisVoice` instance or\n *   structural similar object (if `SpeechSynthesisUtterance` is not supported)\n * @param {number=} options.pitch - Optional pitch value >= 0 and <= 2\n * @param {number=} options.rate - Optional rate value >= 0.1 and <= 10\n * @param {number=} options.volume - Optional volume value >= 0 and <= 1\n * @param {boolean=} options.force - Optional set to true to force speaking, no matter the internal state\n * @param {boolean=} options.infiniteResume - Optional, force or prevent internal resumeInfinity pattern\n * @param {object=} handlers - optional additional local handlers, can be\n *   directly added as top-level properties of the options\n * @param {function=} handlers.boundary - optional, event handler\n * @param {function=} handlers.end - optional, event handler\n * @param {function=} handlers.error - optional, event handler\n * @param {function=} handlers.mark - optional, event handler\n * @param {function=} handlers.pause - optional, event handler\n * @param {function=} handlers.resume - optional, event handler\n * @param {function=} handlers.start - optional, event handler\n *\n *\n * @return {Promise<SpeechSynthesisEvent|SpeechSynthesisErrorEvent>}\n * @fulfill {SpeechSynthesisEvent} Resolves to the `end` event\n * @reject {SpeechSynthesisEvent} rejects using the `error` event\n */\nEasySpeech.speak = ({ text, voice, pitch, rate, volume, force, infiniteResume, ...handlers }) => {\n  ensureInit({ force });\n\n  if (!validate.text(text)) {\n    throw new Error('EasySpeech: at least some valid text is required to speak')\n  }\n\n  const getValue = options => {\n    const [name, value] = Object.entries(options)[0];\n\n    if (validate[name](value)) {\n      return value\n    }\n\n    return internal.defaults?.[name]\n  };\n\n  return new Promise((resolve, reject) => {\n    status('init speak');\n\n    const utterance = createUtterance(text);\n    const currentVoice = getCurrentVoice(voice);\n\n    // XXX: if we force-speak, we may not get a current voice!\n    // This may occur when the browser won't load voices but\n    // provides SpeechSynth and SpeechSynthUtterance.\n    // We then might at least try to speak something with defaults\n    if (currentVoice) {\n      utterance.voice = currentVoice;\n      utterance.lang = currentVoice.lang;\n      utterance.voiceURI = currentVoice.voiceURI;\n    }\n\n    utterance.text = text;\n    utterance.pitch = getValue({ pitch });\n    utterance.rate = getValue({ rate });\n    utterance.volume = getValue({ volume });\n    debugUtterance(utterance);\n\n    utteranceEvents.forEach(name => {\n      const fn = handlers[name];\n\n      if (validate.handler(fn)) {\n        utterance.addEventListener(name, fn);\n      }\n\n      if (internal.handlers?.[name]) {\n        utterance.addEventListener(name, internal.handlers[name]);\n      }\n    });\n\n    // always attached are start, end and error listeners\n\n    // XXX: chrome won't play longer tts texts in one piece and stops after a few\n    // words. We need to add an intervall here in order prevent this. See:\n    // https://stackoverflow.com/questions/21947730/chrome-speech-synthesis-with-longer-texts\n    //\n    // XXX: this apparently works only on chrome desktop, while it breaks chrome\n    // mobile (android), so we need to detect chrome desktop\n    //\n    // XXX: resumeInfinity breaks on firefox macOs so we need to avoid it there\n    // as well. Since we don't need it in FF anyway, we can safely skip there\n    //\n    // XXX: resumeInfinity is also incompatible with older safari ios versions\n    // so we skip it on safari, too.\n    //\n    // XXX: we can force-enable or force-disable infiniteResume via flag now and\n    // use the deterministic approach if it's not a boolean value\n    utterance.addEventListener('start', () => {\n      patches.paused = false;\n      patches.speaking = true;\n\n      const useResumeInfinity = typeof infiniteResume === 'boolean'\n        ? infiniteResume\n        : !patches.isFirefox && !patches.isSafari && patches.isAndroid !== true;\n\n      if (useResumeInfinity) {\n        resumeInfinity(utterance);\n      }\n    });\n\n    utterance.addEventListener('end', endEvent => {\n      status('speak complete');\n      patches.paused = false;\n      patches.speaking = false;\n      clearTimeout(timeoutResumeInfinity);\n      resolve(endEvent);\n    });\n\n    utterance.addEventListener('error', (errorEvent = {}) => {\n      status(`speak failed: ${errorEvent.message}`);\n      patches.paused = false;\n      patches.speaking = false;\n      clearTimeout(timeoutResumeInfinity);\n      reject(errorEvent);\n    });\n\n    // make sure we have no mem-leak\n    clearTimeout(timeoutResumeInfinity);\n    internal.speechSynthesis.cancel();\n\n    setTimeout(() => {\n      internal.speechSynthesis.speak(utterance);\n    }, 10);\n  })\n};\n\n/** @private **/\nconst debugUtterance = ({ voice, pitch, rate, volume }) => {\n  debug(`utterance: voice=${voice?.name} volume=${volume} rate=${rate} pitch=${pitch}`);\n};\n\n/**\n * Timer variable to clear interval\n * @private\n */\nlet timeoutResumeInfinity;\n\n/**\n * Fixes long texts in some browsers\n * @private\n * @param target\n */\nfunction resumeInfinity (target) {\n  // prevent memory-leak in case utterance is deleted, while this is ongoing\n  if (!target && timeoutResumeInfinity) {\n    debug('force-clear timeout');\n    return scope.clearTimeout(timeoutResumeInfinity)\n  }\n\n  // only execute on speaking utterances, otherwise paused\n  // utterances will get resumed, thus breaking user experience\n  // include internal patching, since some systems have problems with\n  // pause/resume and updateing the internal state on speechSynthesis\n  const { paused, speaking } = internal.speechSynthesis;\n  const isSpeaking = speaking || patches.speaking;\n  const isPaused = paused || patches.paused;\n  debug(`resumeInfinity isSpeaking=${isSpeaking} isPaused=${isPaused}`);\n\n  if (isSpeaking && !isPaused) {\n    internal.speechSynthesis.pause();\n    internal.speechSynthesis.resume();\n  }\n  timeoutResumeInfinity = scope.setTimeout(function () {\n    resumeInfinity(target);\n  }, 5000);\n}\n\n/**\n * Cancels the current speaking, if any running\n */\nEasySpeech.cancel = () => {\n  ensureInit();\n  status('cancelling');\n  internal.speechSynthesis.cancel();\n  patches.paused = false;\n  patches.speaking = false;\n};\n\n/**\n * Resumes to speak, if any paused\n */\nEasySpeech.resume = () => {\n  ensureInit();\n  status('resuming');\n\n  patches.paused = false;\n  patches.speaking = true;\n  internal.speechSynthesis.resume();\n};\n\n/**\n * Pauses the current speaking, if any running\n */\nEasySpeech.pause = () => {\n  ensureInit();\n  status('pausing');\n\n  // exec pause on Android causes speech to end but not to fire end-event\n  // se we simply do it manually instead of pausing\n  if (patches.isAndroid) {\n    debug('patch pause on Android with cancel');\n    return internal.speechSynthesis.cancel()\n  }\n\n  internal.speechSynthesis.pause();\n  // in some cases, pause does not update the internal state,\n  // so we need to update it manually using an own state\n  patches.paused = true;\n  patches.speaking = false;\n};\n\n/**\n * Resets the internal state to a default-uninitialized state\n */\nEasySpeech.reset = () => {\n  Object.assign(internal, {\n    status: 'reset',\n    initialized: false,\n    speechSynthesis: null,\n    speechSynthesisUtterance: null,\n    speechSynthesisVoice: null,\n    speechSynthesisEvent: null,\n    speechSynthesisErrorEvent: null,\n    voices: null,\n    defaultVoice: null,\n    defaults: {\n      pitch: 1,\n      rate: 1,\n      volume: 1,\n      voice: null\n    },\n    handlers: {}\n  });\n};\n\nexport { EasySpeech as default };\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","// This script gets injected into any opened page\n// whose URL matches the pattern defined in the manifest\n// (see \"content_script\" key).\n// Several foreground scripts can be declared\n// and injected into the same or different pages.\nimport EasySpeech from 'easy-speech'\n\nEasySpeech.detect()\nEasySpeech.init({ maxTimeout: 5000, interval: 250 })\n\t\t\t.then(() => console.debug('EasySpeech load complete'))\n\t\t\t.catch((e) => console.error(e));\n\nconsole.log(\"ChatGPT Detected! (2)\")\n\nasync function textToSpeech(text, parentButton) {\n  // if ('speechSynthesis' in window) {\n  //   let utterance = new SpeechSynthesisUtterance(text);\n  //   window.speechSynthesis.speak(utterance);\n  // } else {\n  //   console.log('Speech synthesis is not supported in this browser.');\n  // }\n\n  parentButton.lastChild.classList.toggle('hidden') // hide play button\n  parentButton.childNodes[parentButton.childElementCount - 2].classList.toggle('hidden') // show stop button\n\n  let voice = 0;\n  let rate = 1.0;\n\n  chrome.storage.sync.get([\"PROMPTGPT_SPEAK_SPEED\"], function (items) {\n    console.log(items['PROMPTGPT_SPEAK_SPEED'])\n    if (items['PROMPTGPT_SPEAK_SPEED']) {\n      rate = items['PROMPTGPT_SPEAK_SPEED']\n    }\n    chrome.storage.sync.get([\"PROMPTGPT_SPEAK_VOICE\"], async function (items) {\n      console.log(items['PROMPTGPT_SPEAK_VOICE'])\n      if (items['PROMPTGPT_SPEAK_VOICE']) {\n        voice = parseInt(items['PROMPTGPT_SPEAK_VOICE'])\n      }\n\n      await EasySpeech.speak({\n        text,\n        voice: EasySpeech.voices()[voice],\n        pitch: 1,\n        rate,\n        volume: 1,\n        boundary: (e) => console.log('boundary reached'),\n        error: (e) => {\n          console.log('Error during speech: ', e)\n        },\n        mark: (e) => {\n          console.log('marked');\n          console.log(e);\n        }\n      });\n    })\n  })\n\n  \n}\n\n\nif (document.querySelector('textarea')) {\n    document.querySelector('textarea').placeholder = 'I am in charge'\n    \n    let w;\n    if (typeof(Worker) !== \"undefined\") {\n        console.log('Worker is supported by browser')\n        if (typeof(w) == \"undefined\") {\n          w = new Worker(chrome.runtime.getURL(\"worker.js\"));\n          console.log('Worker found, ', w)\n        }\n        w.onmessage = function(event) {\n          let copyButtonList = document.querySelectorAll('path[d=\"M16 4h2a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V6a2 2 0 0 1 2-2h2\"]')\n          \n          for (let elem of copyButtonList) {\n              const parent = elem.parentNode.parentElement.parentNode;\n              if (parent.childElementCount < 3) {\n                const button = document.createRange().createContextualFragment('<button class=\"flex ml-auto gap-2 rounded-md p-1 hover:bg-gray-100 hover:text-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-gray-200 disabled:dark:hover:text-gray-400\"><svg style=\"font-size: larger;\" xmlns=\"http://www.w3.org/2000/svg\" height=\"1em\" width=\"1em\" fill=\"#acacbe\" viewBox=\"0 -960 960 960\"><path d=\"M655-452v-60h145v60H655Zm33 292-119-88 34-47 119 88-34 47Zm-85-505-34-47 119-88 34 47-119 88ZM120-361v-240h160l200-200v640L280-361H120Zm300-288L307-541H180v120h127l113 109v-337Zm-94 168Z\"/></svg></button>')\n                \n                const stopButton = document.createRange().createContextualFragment('<button class=\"hidden flex ml-auto gap-2 rounded-md p-1 hover:bg-gray-100 hover:text-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-gray-200 disabled:dark:hover:text-gray-400\"><svg style=\"font-size: larger;\" xmlns=\"http://www.w3.org/2000/svg\" height=\"1em\" width=\"1em\" fill=\"#acacbe\" viewBox=\"0 -960 960 960\"><path d=\"M300-660v360-360Zm-60 420v-480h480v480H240Zm60-60h360v-360H300v360Z\"/></svg></button>')\n                \n                parent.appendChild(stopButton)\n                parent.appendChild(button)\n\n                // click event for play button\n                parent.lastChild.addEventListener('click', async ()=>{\n                  const text = parent.parentElement.parentNode.firstChild.textContent\n                  await textToSpeech(text, parent);\n                })\n\n                // click event for stop button\n                parent.childNodes[parent.childElementCount - 2].addEventListener('click', ()=>{\n                  parent.lastChild.classList.toggle('hidden') // show play button\n                  parent.childNodes[parent.childElementCount - 2].classList.toggle('hidden') // hide stop button\n                  EasySpeech.cancel()\n                }) \n              } \n          }\n        };\n      } else {\n          console.log(\"Sorry! No Web Worker support.\");\n      }\n}\nelse\n    console.log('Text area not found')\n"],"names":[],"sourceRoot":""}